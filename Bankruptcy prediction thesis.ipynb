{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thesis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOODpHKEnnCU9eOqE4az57u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shidharthbammani11/Bankruptcy-Prediction/blob/master/Bankruptcy%20prediction%20thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVIexG_pv3B-"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "\n",
        "from scipy.io import arff\n",
        "import missingno as msno\n",
        "#import fancyimpute\n",
        "import impyute as impy\n",
        "#from sklearn.preprocessing import Imputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import KFold\n",
        "from collections import Counter\n",
        "from collections import OrderedDict\n",
        "from fancyimpute import IterativeImputer as MICE\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "#from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import * \n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import precision_recall_curve"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ2RuC4a6eRj",
        "outputId": "2aae8fcf-3b8b-40d9-d51e-97dca410b22a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# Loads the 5 raw .arff files into a list\n",
        "def load_arff_raw_data():\n",
        "    N=5\n",
        "    return [arff.loadarff('' + str(i+1) + 'year.arff') for i in range(N)]\n",
        "\n",
        "############################################################\n",
        "# Loads the 5 raw .arff files into pandas dataframes\n",
        "def load_dataframes():\n",
        "    return [pd.DataFrame(data_i_year[0]) for data_i_year in load_arff_raw_data()]\n",
        "\n",
        "############################################################\n",
        "# Set the column headers from X1 ... X64 and the class label as Y, for all the 5 dataframes.\n",
        "def set_new_headers(dataframes):\n",
        "    cols = ['X' + str(i+1) for i in range(len(dataframes[0].columns)-1)]\n",
        "    cols.append('Y')\n",
        "    for df in dataframes:\n",
        "        df.columns = cols\n",
        "\n",
        "############################################################\n",
        "# dataframes is the list of pandas dataframes for the 5 year datafiles.  \n",
        "dataframes = load_dataframes()\n",
        "\n",
        "# Set the new headers for the dataframes. The new headers will have the renamed set of feature (X1 to X64)\n",
        "set_new_headers(dataframes)    \n",
        "\n",
        "# print the first 5 rows of a dataset 'year1'\n",
        "dataframes[0].head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>X11</th>\n",
              "      <th>X12</th>\n",
              "      <th>X13</th>\n",
              "      <th>X14</th>\n",
              "      <th>X15</th>\n",
              "      <th>X16</th>\n",
              "      <th>X17</th>\n",
              "      <th>X18</th>\n",
              "      <th>X19</th>\n",
              "      <th>X20</th>\n",
              "      <th>X21</th>\n",
              "      <th>X22</th>\n",
              "      <th>X23</th>\n",
              "      <th>X24</th>\n",
              "      <th>X25</th>\n",
              "      <th>X26</th>\n",
              "      <th>X27</th>\n",
              "      <th>X28</th>\n",
              "      <th>X29</th>\n",
              "      <th>X30</th>\n",
              "      <th>X31</th>\n",
              "      <th>X32</th>\n",
              "      <th>X33</th>\n",
              "      <th>X34</th>\n",
              "      <th>X35</th>\n",
              "      <th>X36</th>\n",
              "      <th>X37</th>\n",
              "      <th>X38</th>\n",
              "      <th>X39</th>\n",
              "      <th>X40</th>\n",
              "      <th>X41</th>\n",
              "      <th>X42</th>\n",
              "      <th>X43</th>\n",
              "      <th>X44</th>\n",
              "      <th>X45</th>\n",
              "      <th>X46</th>\n",
              "      <th>X47</th>\n",
              "      <th>X48</th>\n",
              "      <th>X49</th>\n",
              "      <th>X50</th>\n",
              "      <th>X51</th>\n",
              "      <th>X52</th>\n",
              "      <th>X53</th>\n",
              "      <th>X54</th>\n",
              "      <th>X55</th>\n",
              "      <th>X56</th>\n",
              "      <th>X57</th>\n",
              "      <th>X58</th>\n",
              "      <th>X59</th>\n",
              "      <th>X60</th>\n",
              "      <th>X61</th>\n",
              "      <th>X62</th>\n",
              "      <th>X63</th>\n",
              "      <th>X64</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.200550</td>\n",
              "      <td>0.37951</td>\n",
              "      <td>0.39641</td>\n",
              "      <td>2.0472</td>\n",
              "      <td>32.3510</td>\n",
              "      <td>0.38825</td>\n",
              "      <td>0.249760</td>\n",
              "      <td>1.33050</td>\n",
              "      <td>1.1389</td>\n",
              "      <td>0.50494</td>\n",
              "      <td>0.249760</td>\n",
              "      <td>0.65980</td>\n",
              "      <td>0.166600</td>\n",
              "      <td>0.249760</td>\n",
              "      <td>497.42</td>\n",
              "      <td>0.73378</td>\n",
              "      <td>2.6349</td>\n",
              "      <td>0.249760</td>\n",
              "      <td>0.149420</td>\n",
              "      <td>43.370</td>\n",
              "      <td>1.2479</td>\n",
              "      <td>0.21402</td>\n",
              "      <td>0.119980</td>\n",
              "      <td>0.47706</td>\n",
              "      <td>0.50494</td>\n",
              "      <td>0.60411</td>\n",
              "      <td>1.45820</td>\n",
              "      <td>1.7615</td>\n",
              "      <td>5.9443</td>\n",
              "      <td>0.11788</td>\n",
              "      <td>0.149420</td>\n",
              "      <td>94.14</td>\n",
              "      <td>3.8772</td>\n",
              "      <td>0.56393</td>\n",
              "      <td>0.21402</td>\n",
              "      <td>1.7410</td>\n",
              "      <td>593.2700</td>\n",
              "      <td>0.50591</td>\n",
              "      <td>0.128040</td>\n",
              "      <td>0.662950</td>\n",
              "      <td>0.051402</td>\n",
              "      <td>0.128040</td>\n",
              "      <td>114.42</td>\n",
              "      <td>71.050</td>\n",
              "      <td>1.00970</td>\n",
              "      <td>1.52250</td>\n",
              "      <td>49.394</td>\n",
              "      <td>0.185300</td>\n",
              "      <td>0.110850</td>\n",
              "      <td>2.0420</td>\n",
              "      <td>0.37854</td>\n",
              "      <td>0.25792</td>\n",
              "      <td>2.2437</td>\n",
              "      <td>2.2480</td>\n",
              "      <td>348690.0</td>\n",
              "      <td>0.121960</td>\n",
              "      <td>0.39718</td>\n",
              "      <td>0.87804</td>\n",
              "      <td>0.001924</td>\n",
              "      <td>8.4160</td>\n",
              "      <td>5.1372</td>\n",
              "      <td>82.658</td>\n",
              "      <td>4.4158</td>\n",
              "      <td>7.4277</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.209120</td>\n",
              "      <td>0.49988</td>\n",
              "      <td>0.47225</td>\n",
              "      <td>1.9447</td>\n",
              "      <td>14.7860</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.258340</td>\n",
              "      <td>0.99601</td>\n",
              "      <td>1.6996</td>\n",
              "      <td>0.49788</td>\n",
              "      <td>0.261140</td>\n",
              "      <td>0.51680</td>\n",
              "      <td>0.158350</td>\n",
              "      <td>0.258340</td>\n",
              "      <td>677.96</td>\n",
              "      <td>0.53838</td>\n",
              "      <td>2.0005</td>\n",
              "      <td>0.258340</td>\n",
              "      <td>0.152000</td>\n",
              "      <td>87.981</td>\n",
              "      <td>1.4293</td>\n",
              "      <td>0.24806</td>\n",
              "      <td>0.123040</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.39542</td>\n",
              "      <td>0.43992</td>\n",
              "      <td>88.44400</td>\n",
              "      <td>16.9460</td>\n",
              "      <td>3.6884</td>\n",
              "      <td>0.26969</td>\n",
              "      <td>0.152000</td>\n",
              "      <td>122.17</td>\n",
              "      <td>2.9876</td>\n",
              "      <td>2.98760</td>\n",
              "      <td>0.20616</td>\n",
              "      <td>1.6996</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.49788</td>\n",
              "      <td>0.121300</td>\n",
              "      <td>0.086422</td>\n",
              "      <td>0.064371</td>\n",
              "      <td>0.145950</td>\n",
              "      <td>199.49</td>\n",
              "      <td>111.510</td>\n",
              "      <td>0.51045</td>\n",
              "      <td>1.12520</td>\n",
              "      <td>100.130</td>\n",
              "      <td>0.237270</td>\n",
              "      <td>0.139610</td>\n",
              "      <td>1.9447</td>\n",
              "      <td>0.49988</td>\n",
              "      <td>0.33472</td>\n",
              "      <td>17.8660</td>\n",
              "      <td>17.8660</td>\n",
              "      <td>2304.6</td>\n",
              "      <td>0.121300</td>\n",
              "      <td>0.42002</td>\n",
              "      <td>0.85300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.1486</td>\n",
              "      <td>3.2732</td>\n",
              "      <td>107.350</td>\n",
              "      <td>3.4000</td>\n",
              "      <td>60.9870</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.248660</td>\n",
              "      <td>0.69592</td>\n",
              "      <td>0.26713</td>\n",
              "      <td>1.5548</td>\n",
              "      <td>-1.1523</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.309060</td>\n",
              "      <td>0.43695</td>\n",
              "      <td>1.3090</td>\n",
              "      <td>0.30408</td>\n",
              "      <td>0.312580</td>\n",
              "      <td>0.64184</td>\n",
              "      <td>0.244350</td>\n",
              "      <td>0.309060</td>\n",
              "      <td>794.16</td>\n",
              "      <td>0.45961</td>\n",
              "      <td>1.4369</td>\n",
              "      <td>0.309060</td>\n",
              "      <td>0.236100</td>\n",
              "      <td>73.133</td>\n",
              "      <td>1.4283</td>\n",
              "      <td>0.30260</td>\n",
              "      <td>0.189960</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.28932</td>\n",
              "      <td>0.37282</td>\n",
              "      <td>86.01100</td>\n",
              "      <td>1.0627</td>\n",
              "      <td>4.3749</td>\n",
              "      <td>0.41929</td>\n",
              "      <td>0.238150</td>\n",
              "      <td>176.93</td>\n",
              "      <td>2.0630</td>\n",
              "      <td>1.42740</td>\n",
              "      <td>0.31565</td>\n",
              "      <td>1.3090</td>\n",
              "      <td>2.3019</td>\n",
              "      <td>0.51537</td>\n",
              "      <td>0.241140</td>\n",
              "      <td>0.322020</td>\n",
              "      <td>0.074020</td>\n",
              "      <td>0.231170</td>\n",
              "      <td>165.51</td>\n",
              "      <td>92.381</td>\n",
              "      <td>0.94807</td>\n",
              "      <td>1.01010</td>\n",
              "      <td>96.372</td>\n",
              "      <td>0.291810</td>\n",
              "      <td>0.222930</td>\n",
              "      <td>1.0758</td>\n",
              "      <td>0.48152</td>\n",
              "      <td>0.48474</td>\n",
              "      <td>1.2098</td>\n",
              "      <td>2.0504</td>\n",
              "      <td>6332.7</td>\n",
              "      <td>0.241140</td>\n",
              "      <td>0.81774</td>\n",
              "      <td>0.76599</td>\n",
              "      <td>0.694840</td>\n",
              "      <td>4.9909</td>\n",
              "      <td>3.9510</td>\n",
              "      <td>134.270</td>\n",
              "      <td>2.7185</td>\n",
              "      <td>5.2078</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.081483</td>\n",
              "      <td>0.30734</td>\n",
              "      <td>0.45879</td>\n",
              "      <td>2.4928</td>\n",
              "      <td>51.9520</td>\n",
              "      <td>0.14988</td>\n",
              "      <td>0.092704</td>\n",
              "      <td>1.86610</td>\n",
              "      <td>1.0571</td>\n",
              "      <td>0.57353</td>\n",
              "      <td>0.092704</td>\n",
              "      <td>0.30163</td>\n",
              "      <td>0.094257</td>\n",
              "      <td>0.092704</td>\n",
              "      <td>917.01</td>\n",
              "      <td>0.39803</td>\n",
              "      <td>3.2537</td>\n",
              "      <td>0.092704</td>\n",
              "      <td>0.071428</td>\n",
              "      <td>79.788</td>\n",
              "      <td>1.5069</td>\n",
              "      <td>0.11550</td>\n",
              "      <td>0.062782</td>\n",
              "      <td>0.17193</td>\n",
              "      <td>0.57353</td>\n",
              "      <td>0.36152</td>\n",
              "      <td>0.94076</td>\n",
              "      <td>1.9618</td>\n",
              "      <td>4.6511</td>\n",
              "      <td>0.14343</td>\n",
              "      <td>0.071428</td>\n",
              "      <td>91.37</td>\n",
              "      <td>3.9948</td>\n",
              "      <td>0.37581</td>\n",
              "      <td>0.11550</td>\n",
              "      <td>1.3562</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.57353</td>\n",
              "      <td>0.088995</td>\n",
              "      <td>0.401390</td>\n",
              "      <td>0.069622</td>\n",
              "      <td>0.088995</td>\n",
              "      <td>180.77</td>\n",
              "      <td>100.980</td>\n",
              "      <td>0.28720</td>\n",
              "      <td>1.56960</td>\n",
              "      <td>84.344</td>\n",
              "      <td>0.085874</td>\n",
              "      <td>0.066165</td>\n",
              "      <td>2.4928</td>\n",
              "      <td>0.30734</td>\n",
              "      <td>0.25033</td>\n",
              "      <td>2.4524</td>\n",
              "      <td>2.4524</td>\n",
              "      <td>20545.0</td>\n",
              "      <td>0.054015</td>\n",
              "      <td>0.14207</td>\n",
              "      <td>0.94598</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.5746</td>\n",
              "      <td>3.6147</td>\n",
              "      <td>86.435</td>\n",
              "      <td>4.2228</td>\n",
              "      <td>5.5497</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.187320</td>\n",
              "      <td>0.61323</td>\n",
              "      <td>0.22960</td>\n",
              "      <td>1.4063</td>\n",
              "      <td>-7.3128</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.187320</td>\n",
              "      <td>0.63070</td>\n",
              "      <td>1.1559</td>\n",
              "      <td>0.38677</td>\n",
              "      <td>0.187320</td>\n",
              "      <td>0.33147</td>\n",
              "      <td>0.121820</td>\n",
              "      <td>0.187320</td>\n",
              "      <td>1133.20</td>\n",
              "      <td>0.32211</td>\n",
              "      <td>1.6307</td>\n",
              "      <td>0.187320</td>\n",
              "      <td>0.115530</td>\n",
              "      <td>57.045</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.19832</td>\n",
              "      <td>0.115530</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.38677</td>\n",
              "      <td>0.32211</td>\n",
              "      <td>1.41380</td>\n",
              "      <td>1.1184</td>\n",
              "      <td>4.1424</td>\n",
              "      <td>0.27884</td>\n",
              "      <td>0.115530</td>\n",
              "      <td>147.04</td>\n",
              "      <td>2.4823</td>\n",
              "      <td>0.32340</td>\n",
              "      <td>0.19832</td>\n",
              "      <td>1.6278</td>\n",
              "      <td>11.2470</td>\n",
              "      <td>0.43489</td>\n",
              "      <td>0.122310</td>\n",
              "      <td>0.293040</td>\n",
              "      <td>0.096680</td>\n",
              "      <td>0.122310</td>\n",
              "      <td>141.62</td>\n",
              "      <td>84.574</td>\n",
              "      <td>0.73919</td>\n",
              "      <td>0.95787</td>\n",
              "      <td>65.936</td>\n",
              "      <td>0.188110</td>\n",
              "      <td>0.116010</td>\n",
              "      <td>1.2959</td>\n",
              "      <td>0.56511</td>\n",
              "      <td>0.40285</td>\n",
              "      <td>1.8839</td>\n",
              "      <td>2.1184</td>\n",
              "      <td>3186.6</td>\n",
              "      <td>0.134850</td>\n",
              "      <td>0.48431</td>\n",
              "      <td>0.86515</td>\n",
              "      <td>0.124440</td>\n",
              "      <td>6.3985</td>\n",
              "      <td>4.3158</td>\n",
              "      <td>127.210</td>\n",
              "      <td>2.8692</td>\n",
              "      <td>7.8980</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         X1       X2       X3      X4  ...      X62     X63      X64     Y\n",
              "0  0.200550  0.37951  0.39641  2.0472  ...   82.658  4.4158   7.4277  b'0'\n",
              "1  0.209120  0.49988  0.47225  1.9447  ...  107.350  3.4000  60.9870  b'0'\n",
              "2  0.248660  0.69592  0.26713  1.5548  ...  134.270  2.7185   5.2078  b'0'\n",
              "3  0.081483  0.30734  0.45879  2.4928  ...   86.435  4.2228   5.5497  b'0'\n",
              "4  0.187320  0.61323  0.22960  1.4063  ...  127.210  2.8692   7.8980  b'0'\n",
              "\n",
              "[5 rows x 65 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35vPqavv6fW6"
      },
      "source": [
        "# Convert the dtypes of all the columns (other than the class label columns) to float.\n",
        "def convert_columns_type_float(dfs):\n",
        "    for i in range(5):\n",
        "        index = 1\n",
        "        while(index<=63):\n",
        "            colname = dfs[i].columns[index]\n",
        "            col = getattr(dfs[i], colname)\n",
        "            dfs[i][colname] = col.astype(float)\n",
        "            index+=1\n",
        "            \n",
        "convert_columns_type_float(dataframes)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M_EmE216iU0"
      },
      "source": [
        "# The class labels for all the dataframes are originally in object type.\n",
        "# Convert them to int types\n",
        "def convert_class_label_type_int(dfs):\n",
        "    for i in range(len(dfs)):\n",
        "        col = getattr(dfs[i], 'Y')\n",
        "        dfs[i]['Y'] = col.astype(int)\n",
        "        \n",
        "convert_class_label_type_int(dataframes)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llqt6_iD6kWA",
        "outputId": "8c7ed0ca-f8fb-472c-a462-fd2fb777a41c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "############################################################\n",
        "# Get Clean dataframes by dropping all the rows which have missing values\n",
        "def drop_nan_rows(dataframes, verbose=False):\n",
        "    clean_dataframes = [df.dropna(axis=0, how='any') for df in dataframes]\n",
        "    if verbose:\n",
        "        for i in range(len(dataframes)):\n",
        "            print(str(i+1)+'year:','Original Length=', len(dataframes[i]), '\\tCleaned Length=', len(clean_dataframes[i]), '\\tMissing Data=', len(dataframes[i])-len(clean_dataframes[i]))\n",
        "    return clean_dataframes\n",
        "\n",
        "# Doing a quick analysis of how many missing values are there in each of the 5 dataframes\n",
        "nan_dropped_dataframes = drop_nan_rows(dataframes, verbose=True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1year: Original Length= 7027 \tCleaned Length= 3194 \tMissing Data= 3833\n",
            "2year: Original Length= 10173 \tCleaned Length= 4088 \tMissing Data= 6085\n",
            "3year: Original Length= 10503 \tCleaned Length= 4885 \tMissing Data= 5618\n",
            "4year: Original Length= 9792 \tCleaned Length= 4769 \tMissing Data= 5023\n",
            "5year: Original Length= 5910 \tCleaned Length= 3031 \tMissing Data= 2879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaJq5q1rFKUS"
      },
      "source": [
        "def mean_imputation(dfs):\n",
        "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean', fill_value=None, verbose=0, copy=True)\n",
        "    #imputer = Imputer(missing_values=np.nan, strategy='mean', axis=0)\n",
        "    mean_imputed_dfs = [pd.DataFrame(imputer.fit_transform(df)) for df in dfs]\n",
        "    for i in range(len(dfs)):\n",
        "        mean_imputed_dfs[i].columns = dfs[i].columns   \n",
        "    return mean_imputed_dfs\n",
        "\n",
        "mean_imputed_dataframes = mean_imputation(dataframes)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qnx90lu6v2S",
        "outputId": "d13aeb32-f8fc-41df-cd31-6ac8f4abc387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def perform_knn_imputation(dfs):\n",
        "    knn_imputed_datasets = [fancyimpute.KNN(k=100,verbose=True).fit_transform(dfs[i]) for i in range(len(dfs))]\n",
        "    return [pd.DataFrame(data=knn_imputed_datasets[i]) for i in range(len(dfs))]\n",
        "    \n",
        "knn_imputed_dataframes = perform_knn_imputation(dataframes)\n",
        "set_new_headers(knn_imputed_dataframes)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imputing row 1/7027 with 0 missing, elapsed time: 19.275\n",
            "Imputing row 101/7027 with 1 missing, elapsed time: 19.283\n",
            "Imputing row 201/7027 with 2 missing, elapsed time: 19.292\n",
            "Imputing row 301/7027 with 0 missing, elapsed time: 19.299\n",
            "Imputing row 401/7027 with 0 missing, elapsed time: 19.305\n",
            "Imputing row 501/7027 with 1 missing, elapsed time: 19.311\n",
            "Imputing row 601/7027 with 1 missing, elapsed time: 19.317\n",
            "Imputing row 701/7027 with 1 missing, elapsed time: 19.324\n",
            "Imputing row 801/7027 with 0 missing, elapsed time: 19.329\n",
            "Imputing row 901/7027 with 0 missing, elapsed time: 19.335\n",
            "Imputing row 1001/7027 with 1 missing, elapsed time: 19.342\n",
            "Imputing row 1101/7027 with 1 missing, elapsed time: 19.348\n",
            "Imputing row 1201/7027 with 3 missing, elapsed time: 19.355\n",
            "Imputing row 1301/7027 with 1 missing, elapsed time: 19.361\n",
            "Imputing row 1401/7027 with 1 missing, elapsed time: 19.367\n",
            "Imputing row 1501/7027 with 1 missing, elapsed time: 19.374\n",
            "Imputing row 1601/7027 with 1 missing, elapsed time: 19.381\n",
            "Imputing row 1701/7027 with 2 missing, elapsed time: 19.387\n",
            "Imputing row 1801/7027 with 1 missing, elapsed time: 19.393\n",
            "Imputing row 1901/7027 with 33 missing, elapsed time: 19.401\n",
            "Imputing row 2001/7027 with 0 missing, elapsed time: 19.407\n",
            "Imputing row 2101/7027 with 2 missing, elapsed time: 19.413\n",
            "Imputing row 2201/7027 with 1 missing, elapsed time: 19.419\n",
            "Imputing row 2301/7027 with 1 missing, elapsed time: 19.426\n",
            "Imputing row 2401/7027 with 0 missing, elapsed time: 19.432\n",
            "Imputing row 2501/7027 with 1 missing, elapsed time: 19.440\n",
            "Imputing row 2601/7027 with 0 missing, elapsed time: 19.447\n",
            "Imputing row 2701/7027 with 0 missing, elapsed time: 19.456\n",
            "Imputing row 2801/7027 with 1 missing, elapsed time: 19.461\n",
            "Imputing row 2901/7027 with 1 missing, elapsed time: 19.468\n",
            "Imputing row 3001/7027 with 0 missing, elapsed time: 19.475\n",
            "Imputing row 3101/7027 with 2 missing, elapsed time: 19.485\n",
            "Imputing row 3201/7027 with 1 missing, elapsed time: 19.492\n",
            "Imputing row 3301/7027 with 0 missing, elapsed time: 19.497\n",
            "Imputing row 3401/7027 with 0 missing, elapsed time: 19.503\n",
            "Imputing row 3501/7027 with 0 missing, elapsed time: 19.509\n",
            "Imputing row 3601/7027 with 1 missing, elapsed time: 19.515\n",
            "Imputing row 3701/7027 with 1 missing, elapsed time: 19.523\n",
            "Imputing row 3801/7027 with 0 missing, elapsed time: 19.529\n",
            "Imputing row 3901/7027 with 0 missing, elapsed time: 19.533\n",
            "Imputing row 4001/7027 with 1 missing, elapsed time: 19.539\n",
            "Imputing row 4101/7027 with 1 missing, elapsed time: 19.543\n",
            "Imputing row 4201/7027 with 1 missing, elapsed time: 19.548\n",
            "Imputing row 4301/7027 with 1 missing, elapsed time: 19.554\n",
            "Imputing row 4401/7027 with 0 missing, elapsed time: 19.559\n",
            "Imputing row 4501/7027 with 0 missing, elapsed time: 19.566\n",
            "Imputing row 4601/7027 with 0 missing, elapsed time: 19.572\n",
            "Imputing row 4701/7027 with 1 missing, elapsed time: 19.577\n",
            "Imputing row 4801/7027 with 0 missing, elapsed time: 19.582\n",
            "Imputing row 4901/7027 with 1 missing, elapsed time: 19.586\n",
            "Imputing row 5001/7027 with 1 missing, elapsed time: 19.593\n",
            "Imputing row 5101/7027 with 0 missing, elapsed time: 19.599\n",
            "Imputing row 5201/7027 with 0 missing, elapsed time: 19.603\n",
            "Imputing row 5301/7027 with 1 missing, elapsed time: 19.609\n",
            "Imputing row 5401/7027 with 0 missing, elapsed time: 19.615\n",
            "Imputing row 5501/7027 with 0 missing, elapsed time: 19.620\n",
            "Imputing row 5601/7027 with 9 missing, elapsed time: 19.624\n",
            "Imputing row 5701/7027 with 2 missing, elapsed time: 19.627\n",
            "Imputing row 5801/7027 with 0 missing, elapsed time: 19.633\n",
            "Imputing row 5901/7027 with 1 missing, elapsed time: 19.639\n",
            "Imputing row 6001/7027 with 0 missing, elapsed time: 19.646\n",
            "Imputing row 6101/7027 with 0 missing, elapsed time: 19.653\n",
            "Imputing row 6201/7027 with 0 missing, elapsed time: 19.660\n",
            "Imputing row 6301/7027 with 0 missing, elapsed time: 19.666\n",
            "Imputing row 6401/7027 with 1 missing, elapsed time: 19.671\n",
            "Imputing row 6501/7027 with 3 missing, elapsed time: 19.677\n",
            "Imputing row 6601/7027 with 0 missing, elapsed time: 19.683\n",
            "Imputing row 6701/7027 with 1 missing, elapsed time: 19.691\n",
            "Imputing row 6801/7027 with 1 missing, elapsed time: 19.700\n",
            "Imputing row 6901/7027 with 1 missing, elapsed time: 19.709\n",
            "Imputing row 7001/7027 with 3 missing, elapsed time: 19.718\n",
            "Imputing row 1/10173 with 0 missing, elapsed time: 42.490\n",
            "Imputing row 101/10173 with 3 missing, elapsed time: 42.502\n",
            "Imputing row 201/10173 with 0 missing, elapsed time: 42.514\n",
            "Imputing row 301/10173 with 1 missing, elapsed time: 42.528\n",
            "Imputing row 401/10173 with 0 missing, elapsed time: 42.542\n",
            "Imputing row 501/10173 with 0 missing, elapsed time: 42.552\n",
            "Imputing row 601/10173 with 0 missing, elapsed time: 42.562\n",
            "Imputing row 701/10173 with 1 missing, elapsed time: 42.571\n",
            "Imputing row 801/10173 with 0 missing, elapsed time: 42.579\n",
            "Imputing row 901/10173 with 1 missing, elapsed time: 42.590\n",
            "Imputing row 1001/10173 with 0 missing, elapsed time: 42.600\n",
            "Imputing row 1101/10173 with 2 missing, elapsed time: 42.611\n",
            "Imputing row 1201/10173 with 1 missing, elapsed time: 42.622\n",
            "Imputing row 1301/10173 with 0 missing, elapsed time: 42.636\n",
            "Imputing row 1401/10173 with 0 missing, elapsed time: 42.650\n",
            "Imputing row 1501/10173 with 4 missing, elapsed time: 42.661\n",
            "Imputing row 1601/10173 with 0 missing, elapsed time: 42.673\n",
            "Imputing row 1701/10173 with 1 missing, elapsed time: 42.684\n",
            "Imputing row 1801/10173 with 0 missing, elapsed time: 42.697\n",
            "Imputing row 1901/10173 with 1 missing, elapsed time: 42.712\n",
            "Imputing row 2001/10173 with 1 missing, elapsed time: 42.723\n",
            "Imputing row 2101/10173 with 0 missing, elapsed time: 42.736\n",
            "Imputing row 2201/10173 with 0 missing, elapsed time: 42.747\n",
            "Imputing row 2301/10173 with 1 missing, elapsed time: 42.757\n",
            "Imputing row 2401/10173 with 0 missing, elapsed time: 42.768\n",
            "Imputing row 2501/10173 with 1 missing, elapsed time: 42.779\n",
            "Imputing row 2601/10173 with 1 missing, elapsed time: 42.790\n",
            "Imputing row 2701/10173 with 0 missing, elapsed time: 42.800\n",
            "Imputing row 2801/10173 with 1 missing, elapsed time: 42.810\n",
            "Imputing row 2901/10173 with 2 missing, elapsed time: 42.818\n",
            "Imputing row 3001/10173 with 1 missing, elapsed time: 42.830\n",
            "Imputing row 3101/10173 with 0 missing, elapsed time: 42.840\n",
            "Imputing row 3201/10173 with 2 missing, elapsed time: 42.850\n",
            "Imputing row 3301/10173 with 1 missing, elapsed time: 42.862\n",
            "Imputing row 3401/10173 with 1 missing, elapsed time: 42.874\n",
            "Imputing row 3501/10173 with 0 missing, elapsed time: 42.889\n",
            "Imputing row 3601/10173 with 0 missing, elapsed time: 42.903\n",
            "Imputing row 3701/10173 with 4 missing, elapsed time: 42.918\n",
            "Imputing row 3801/10173 with 1 missing, elapsed time: 42.936\n",
            "Imputing row 3901/10173 with 1 missing, elapsed time: 42.953\n",
            "Imputing row 4001/10173 with 1 missing, elapsed time: 42.967\n",
            "Imputing row 4101/10173 with 0 missing, elapsed time: 42.977\n",
            "Imputing row 4201/10173 with 33 missing, elapsed time: 42.988\n",
            "Imputing row 4301/10173 with 0 missing, elapsed time: 43.001\n",
            "Imputing row 4401/10173 with 2 missing, elapsed time: 43.018\n",
            "Imputing row 4501/10173 with 0 missing, elapsed time: 43.028\n",
            "Imputing row 4601/10173 with 0 missing, elapsed time: 43.041\n",
            "Imputing row 4701/10173 with 4 missing, elapsed time: 43.054\n",
            "Imputing row 4801/10173 with 0 missing, elapsed time: 43.064\n",
            "Imputing row 4901/10173 with 1 missing, elapsed time: 43.072\n",
            "Imputing row 5001/10173 with 2 missing, elapsed time: 43.082\n",
            "Imputing row 5101/10173 with 1 missing, elapsed time: 43.091\n",
            "Imputing row 5201/10173 with 1 missing, elapsed time: 43.099\n",
            "Imputing row 5301/10173 with 1 missing, elapsed time: 43.117\n",
            "Imputing row 5401/10173 with 1 missing, elapsed time: 43.131\n",
            "Imputing row 5501/10173 with 1 missing, elapsed time: 43.145\n",
            "Imputing row 5601/10173 with 1 missing, elapsed time: 43.155\n",
            "Imputing row 5701/10173 with 2 missing, elapsed time: 43.163\n",
            "Imputing row 5801/10173 with 2 missing, elapsed time: 43.173\n",
            "Imputing row 5901/10173 with 1 missing, elapsed time: 43.182\n",
            "Imputing row 6001/10173 with 0 missing, elapsed time: 43.191\n",
            "Imputing row 6101/10173 with 6 missing, elapsed time: 43.200\n",
            "Imputing row 6201/10173 with 0 missing, elapsed time: 43.214\n",
            "Imputing row 6301/10173 with 0 missing, elapsed time: 43.224\n",
            "Imputing row 6401/10173 with 1 missing, elapsed time: 43.236\n",
            "Imputing row 6501/10173 with 1 missing, elapsed time: 43.253\n",
            "Imputing row 6601/10173 with 1 missing, elapsed time: 43.264\n",
            "Imputing row 6701/10173 with 5 missing, elapsed time: 43.279\n",
            "Imputing row 6801/10173 with 0 missing, elapsed time: 43.287\n",
            "Imputing row 6901/10173 with 2 missing, elapsed time: 43.294\n",
            "Imputing row 7001/10173 with 2 missing, elapsed time: 43.303\n",
            "Imputing row 7101/10173 with 2 missing, elapsed time: 43.311\n",
            "Imputing row 7201/10173 with 1 missing, elapsed time: 43.320\n",
            "Imputing row 7301/10173 with 1 missing, elapsed time: 43.335\n",
            "Imputing row 7401/10173 with 3 missing, elapsed time: 43.350\n",
            "Imputing row 7501/10173 with 0 missing, elapsed time: 43.358\n",
            "Imputing row 7601/10173 with 0 missing, elapsed time: 43.364\n",
            "Imputing row 7701/10173 with 1 missing, elapsed time: 43.371\n",
            "Imputing row 7801/10173 with 0 missing, elapsed time: 43.379\n",
            "Imputing row 7901/10173 with 1 missing, elapsed time: 43.386\n",
            "Imputing row 8001/10173 with 0 missing, elapsed time: 43.395\n",
            "Imputing row 8101/10173 with 0 missing, elapsed time: 43.404\n",
            "Imputing row 8201/10173 with 0 missing, elapsed time: 43.408\n",
            "Imputing row 8301/10173 with 1 missing, elapsed time: 43.417\n",
            "Imputing row 8401/10173 with 0 missing, elapsed time: 43.430\n",
            "Imputing row 8501/10173 with 3 missing, elapsed time: 43.439\n",
            "Imputing row 8601/10173 with 0 missing, elapsed time: 43.452\n",
            "Imputing row 8701/10173 with 0 missing, elapsed time: 43.463\n",
            "Imputing row 8801/10173 with 0 missing, elapsed time: 43.473\n",
            "Imputing row 8901/10173 with 2 missing, elapsed time: 43.486\n",
            "Imputing row 9001/10173 with 2 missing, elapsed time: 43.498\n",
            "Imputing row 9101/10173 with 2 missing, elapsed time: 43.510\n",
            "Imputing row 9201/10173 with 0 missing, elapsed time: 43.520\n",
            "Imputing row 9301/10173 with 1 missing, elapsed time: 43.539\n",
            "Imputing row 9401/10173 with 0 missing, elapsed time: 43.554\n",
            "Imputing row 9501/10173 with 2 missing, elapsed time: 43.565\n",
            "Imputing row 9601/10173 with 0 missing, elapsed time: 43.574\n",
            "Imputing row 9701/10173 with 1 missing, elapsed time: 43.584\n",
            "Imputing row 9801/10173 with 1 missing, elapsed time: 43.595\n",
            "Imputing row 9901/10173 with 1 missing, elapsed time: 43.609\n",
            "Imputing row 10001/10173 with 1 missing, elapsed time: 43.624\n",
            "Imputing row 10101/10173 with 0 missing, elapsed time: 43.638\n",
            "Imputing row 1/10503 with 0 missing, elapsed time: 44.280\n",
            "Imputing row 101/10503 with 0 missing, elapsed time: 44.292\n",
            "Imputing row 201/10503 with 2 missing, elapsed time: 44.303\n",
            "Imputing row 301/10503 with 1 missing, elapsed time: 44.314\n",
            "Imputing row 401/10503 with 0 missing, elapsed time: 44.326\n",
            "Imputing row 501/10503 with 1 missing, elapsed time: 44.333\n",
            "Imputing row 601/10503 with 0 missing, elapsed time: 44.340\n",
            "Imputing row 701/10503 with 1 missing, elapsed time: 44.348\n",
            "Imputing row 801/10503 with 0 missing, elapsed time: 44.355\n",
            "Imputing row 901/10503 with 1 missing, elapsed time: 44.364\n",
            "Imputing row 1001/10503 with 1 missing, elapsed time: 44.372\n",
            "Imputing row 1101/10503 with 1 missing, elapsed time: 44.380\n",
            "Imputing row 1201/10503 with 0 missing, elapsed time: 44.391\n",
            "Imputing row 1301/10503 with 2 missing, elapsed time: 44.404\n",
            "Imputing row 1401/10503 with 1 missing, elapsed time: 44.414\n",
            "Imputing row 1501/10503 with 4 missing, elapsed time: 44.424\n",
            "Imputing row 1601/10503 with 1 missing, elapsed time: 44.434\n",
            "Imputing row 1701/10503 with 0 missing, elapsed time: 44.444\n",
            "Imputing row 1801/10503 with 1 missing, elapsed time: 44.452\n",
            "Imputing row 1901/10503 with 0 missing, elapsed time: 44.463\n",
            "Imputing row 2001/10503 with 1 missing, elapsed time: 44.474\n",
            "Imputing row 2101/10503 with 1 missing, elapsed time: 44.488\n",
            "Imputing row 2201/10503 with 0 missing, elapsed time: 44.498\n",
            "Imputing row 2301/10503 with 0 missing, elapsed time: 44.506\n",
            "Imputing row 2401/10503 with 0 missing, elapsed time: 44.513\n",
            "Imputing row 2501/10503 with 3 missing, elapsed time: 44.521\n",
            "Imputing row 2601/10503 with 1 missing, elapsed time: 44.528\n",
            "Imputing row 2701/10503 with 0 missing, elapsed time: 44.537\n",
            "Imputing row 2801/10503 with 1 missing, elapsed time: 44.546\n",
            "Imputing row 2901/10503 with 0 missing, elapsed time: 44.554\n",
            "Imputing row 3001/10503 with 1 missing, elapsed time: 44.560\n",
            "Imputing row 3101/10503 with 0 missing, elapsed time: 44.567\n",
            "Imputing row 3201/10503 with 0 missing, elapsed time: 44.574\n",
            "Imputing row 3301/10503 with 1 missing, elapsed time: 44.583\n",
            "Imputing row 3401/10503 with 0 missing, elapsed time: 44.593\n",
            "Imputing row 3501/10503 with 1 missing, elapsed time: 44.601\n",
            "Imputing row 3601/10503 with 0 missing, elapsed time: 44.613\n",
            "Imputing row 3701/10503 with 1 missing, elapsed time: 44.623\n",
            "Imputing row 3801/10503 with 2 missing, elapsed time: 44.633\n",
            "Imputing row 3901/10503 with 0 missing, elapsed time: 44.644\n",
            "Imputing row 4001/10503 with 0 missing, elapsed time: 44.654\n",
            "Imputing row 4101/10503 with 1 missing, elapsed time: 44.664\n",
            "Imputing row 4201/10503 with 1 missing, elapsed time: 44.673\n",
            "Imputing row 4301/10503 with 0 missing, elapsed time: 44.680\n",
            "Imputing row 4401/10503 with 1 missing, elapsed time: 44.695\n",
            "Imputing row 4501/10503 with 2 missing, elapsed time: 44.708\n",
            "Imputing row 4601/10503 with 1 missing, elapsed time: 44.716\n",
            "Imputing row 4701/10503 with 2 missing, elapsed time: 44.726\n",
            "Imputing row 4801/10503 with 0 missing, elapsed time: 44.737\n",
            "Imputing row 4901/10503 with 1 missing, elapsed time: 44.745\n",
            "Imputing row 5001/10503 with 0 missing, elapsed time: 44.754\n",
            "Imputing row 5101/10503 with 1 missing, elapsed time: 44.763\n",
            "Imputing row 5201/10503 with 0 missing, elapsed time: 44.771\n",
            "Imputing row 5301/10503 with 2 missing, elapsed time: 44.780\n",
            "Imputing row 5401/10503 with 3 missing, elapsed time: 44.789\n",
            "Imputing row 5501/10503 with 2 missing, elapsed time: 44.802\n",
            "Imputing row 5601/10503 with 1 missing, elapsed time: 44.812\n",
            "Imputing row 5701/10503 with 0 missing, elapsed time: 44.821\n",
            "Imputing row 5801/10503 with 0 missing, elapsed time: 44.828\n",
            "Imputing row 5901/10503 with 1 missing, elapsed time: 44.835\n",
            "Imputing row 6001/10503 with 1 missing, elapsed time: 44.843\n",
            "Imputing row 6101/10503 with 0 missing, elapsed time: 44.851\n",
            "Imputing row 6201/10503 with 0 missing, elapsed time: 44.859\n",
            "Imputing row 6301/10503 with 1 missing, elapsed time: 44.870\n",
            "Imputing row 6401/10503 with 0 missing, elapsed time: 44.879\n",
            "Imputing row 6501/10503 with 0 missing, elapsed time: 44.887\n",
            "Imputing row 6601/10503 with 0 missing, elapsed time: 44.897\n",
            "Imputing row 6701/10503 with 0 missing, elapsed time: 44.910\n",
            "Imputing row 6801/10503 with 2 missing, elapsed time: 44.919\n",
            "Imputing row 6901/10503 with 3 missing, elapsed time: 44.931\n",
            "Imputing row 7001/10503 with 1 missing, elapsed time: 44.938\n",
            "Imputing row 7101/10503 with 0 missing, elapsed time: 44.943\n",
            "Imputing row 7201/10503 with 3 missing, elapsed time: 44.950\n",
            "Imputing row 7301/10503 with 0 missing, elapsed time: 44.957\n",
            "Imputing row 7401/10503 with 1 missing, elapsed time: 44.965\n",
            "Imputing row 7501/10503 with 0 missing, elapsed time: 44.975\n",
            "Imputing row 7601/10503 with 0 missing, elapsed time: 44.983\n",
            "Imputing row 7701/10503 with 0 missing, elapsed time: 44.989\n",
            "Imputing row 7801/10503 with 2 missing, elapsed time: 44.994\n",
            "Imputing row 7901/10503 with 0 missing, elapsed time: 45.000\n",
            "Imputing row 8001/10503 with 1 missing, elapsed time: 45.006\n",
            "Imputing row 8101/10503 with 1 missing, elapsed time: 45.015\n",
            "Imputing row 8201/10503 with 0 missing, elapsed time: 45.022\n",
            "Imputing row 8301/10503 with 0 missing, elapsed time: 45.029\n",
            "Imputing row 8401/10503 with 1 missing, elapsed time: 45.035\n",
            "Imputing row 8501/10503 with 1 missing, elapsed time: 45.044\n",
            "Imputing row 8601/10503 with 1 missing, elapsed time: 45.053\n",
            "Imputing row 8701/10503 with 1 missing, elapsed time: 45.063\n",
            "Imputing row 8801/10503 with 0 missing, elapsed time: 45.071\n",
            "Imputing row 8901/10503 with 2 missing, elapsed time: 45.079\n",
            "Imputing row 9001/10503 with 2 missing, elapsed time: 45.087\n",
            "Imputing row 9101/10503 with 0 missing, elapsed time: 45.097\n",
            "Imputing row 9201/10503 with 0 missing, elapsed time: 45.108\n",
            "Imputing row 9301/10503 with 0 missing, elapsed time: 45.116\n",
            "Imputing row 9401/10503 with 0 missing, elapsed time: 45.125\n",
            "Imputing row 9501/10503 with 0 missing, elapsed time: 45.132\n",
            "Imputing row 9601/10503 with 1 missing, elapsed time: 45.139\n",
            "Imputing row 9701/10503 with 1 missing, elapsed time: 45.148\n",
            "Imputing row 9801/10503 with 1 missing, elapsed time: 45.157\n",
            "Imputing row 9901/10503 with 0 missing, elapsed time: 45.164\n",
            "Imputing row 10001/10503 with 1 missing, elapsed time: 45.171\n",
            "Imputing row 10101/10503 with 0 missing, elapsed time: 45.179\n",
            "Imputing row 10201/10503 with 1 missing, elapsed time: 45.189\n",
            "Imputing row 10301/10503 with 0 missing, elapsed time: 45.200\n",
            "Imputing row 10401/10503 with 1 missing, elapsed time: 45.217\n",
            "Imputing row 10501/10503 with 1 missing, elapsed time: 45.229\n",
            "Imputing row 1/9792 with 0 missing, elapsed time: 39.491\n",
            "Imputing row 101/9792 with 0 missing, elapsed time: 39.502\n",
            "Imputing row 201/9792 with 0 missing, elapsed time: 39.511\n",
            "Imputing row 301/9792 with 1 missing, elapsed time: 39.523\n",
            "Imputing row 401/9792 with 3 missing, elapsed time: 39.532\n",
            "Imputing row 501/9792 with 0 missing, elapsed time: 39.538\n",
            "Imputing row 601/9792 with 1 missing, elapsed time: 39.545\n",
            "Imputing row 701/9792 with 3 missing, elapsed time: 39.551\n",
            "Imputing row 801/9792 with 1 missing, elapsed time: 39.559\n",
            "Imputing row 901/9792 with 0 missing, elapsed time: 39.566\n",
            "Imputing row 1001/9792 with 0 missing, elapsed time: 39.575\n",
            "Imputing row 1101/9792 with 1 missing, elapsed time: 39.582\n",
            "Imputing row 1201/9792 with 3 missing, elapsed time: 39.590\n",
            "Imputing row 1301/9792 with 0 missing, elapsed time: 39.598\n",
            "Imputing row 1401/9792 with 1 missing, elapsed time: 39.607\n",
            "Imputing row 1501/9792 with 0 missing, elapsed time: 39.615\n",
            "Imputing row 1601/9792 with 1 missing, elapsed time: 39.623\n",
            "Imputing row 1701/9792 with 0 missing, elapsed time: 39.631\n",
            "Imputing row 1801/9792 with 1 missing, elapsed time: 39.639\n",
            "Imputing row 1901/9792 with 0 missing, elapsed time: 39.649\n",
            "Imputing row 2001/9792 with 0 missing, elapsed time: 39.658\n",
            "Imputing row 2101/9792 with 1 missing, elapsed time: 39.666\n",
            "Imputing row 2201/9792 with 1 missing, elapsed time: 39.673\n",
            "Imputing row 2301/9792 with 1 missing, elapsed time: 39.680\n",
            "Imputing row 2401/9792 with 0 missing, elapsed time: 39.686\n",
            "Imputing row 2501/9792 with 0 missing, elapsed time: 39.695\n",
            "Imputing row 2601/9792 with 1 missing, elapsed time: 39.706\n",
            "Imputing row 2701/9792 with 0 missing, elapsed time: 39.714\n",
            "Imputing row 2801/9792 with 0 missing, elapsed time: 39.721\n",
            "Imputing row 2901/9792 with 0 missing, elapsed time: 39.729\n",
            "Imputing row 3001/9792 with 1 missing, elapsed time: 39.735\n",
            "Imputing row 3101/9792 with 1 missing, elapsed time: 39.744\n",
            "Imputing row 3201/9792 with 0 missing, elapsed time: 39.752\n",
            "Imputing row 3301/9792 with 0 missing, elapsed time: 39.760\n",
            "Imputing row 3401/9792 with 1 missing, elapsed time: 39.770\n",
            "Imputing row 3501/9792 with 1 missing, elapsed time: 39.778\n",
            "Imputing row 3601/9792 with 3 missing, elapsed time: 39.788\n",
            "Imputing row 3701/9792 with 1 missing, elapsed time: 39.796\n",
            "Imputing row 3801/9792 with 1 missing, elapsed time: 39.806\n",
            "Imputing row 3901/9792 with 0 missing, elapsed time: 39.814\n",
            "Imputing row 4001/9792 with 0 missing, elapsed time: 39.822\n",
            "Imputing row 4101/9792 with 0 missing, elapsed time: 39.833\n",
            "Imputing row 4201/9792 with 0 missing, elapsed time: 39.846\n",
            "Imputing row 4301/9792 with 1 missing, elapsed time: 39.854\n",
            "Imputing row 4401/9792 with 0 missing, elapsed time: 39.862\n",
            "Imputing row 4501/9792 with 1 missing, elapsed time: 39.870\n",
            "Imputing row 4601/9792 with 2 missing, elapsed time: 39.878\n",
            "Imputing row 4701/9792 with 0 missing, elapsed time: 39.884\n",
            "Imputing row 4801/9792 with 3 missing, elapsed time: 39.891\n",
            "Imputing row 4901/9792 with 0 missing, elapsed time: 39.897\n",
            "Imputing row 5001/9792 with 1 missing, elapsed time: 39.906\n",
            "Imputing row 5101/9792 with 1 missing, elapsed time: 39.917\n",
            "Imputing row 5201/9792 with 0 missing, elapsed time: 39.928\n",
            "Imputing row 5301/9792 with 1 missing, elapsed time: 39.935\n",
            "Imputing row 5401/9792 with 0 missing, elapsed time: 39.942\n",
            "Imputing row 5501/9792 with 2 missing, elapsed time: 39.947\n",
            "Imputing row 5601/9792 with 0 missing, elapsed time: 39.954\n",
            "Imputing row 5701/9792 with 3 missing, elapsed time: 39.962\n",
            "Imputing row 5801/9792 with 8 missing, elapsed time: 39.968\n",
            "Imputing row 5901/9792 with 0 missing, elapsed time: 39.978\n",
            "Imputing row 6001/9792 with 0 missing, elapsed time: 39.985\n",
            "Imputing row 6101/9792 with 0 missing, elapsed time: 39.992\n",
            "Imputing row 6201/9792 with 2 missing, elapsed time: 40.004\n",
            "Imputing row 6301/9792 with 1 missing, elapsed time: 40.012\n",
            "Imputing row 6401/9792 with 1 missing, elapsed time: 40.023\n",
            "Imputing row 6501/9792 with 0 missing, elapsed time: 40.032\n",
            "Imputing row 6601/9792 with 1 missing, elapsed time: 40.037\n",
            "Imputing row 6701/9792 with 1 missing, elapsed time: 40.045\n",
            "Imputing row 6801/9792 with 0 missing, elapsed time: 40.052\n",
            "Imputing row 6901/9792 with 0 missing, elapsed time: 40.060\n",
            "Imputing row 7001/9792 with 0 missing, elapsed time: 40.066\n",
            "Imputing row 7101/9792 with 1 missing, elapsed time: 40.072\n",
            "Imputing row 7201/9792 with 2 missing, elapsed time: 40.077\n",
            "Imputing row 7301/9792 with 0 missing, elapsed time: 40.083\n",
            "Imputing row 7401/9792 with 0 missing, elapsed time: 40.088\n",
            "Imputing row 7501/9792 with 1 missing, elapsed time: 40.094\n",
            "Imputing row 7601/9792 with 0 missing, elapsed time: 40.100\n",
            "Imputing row 7701/9792 with 0 missing, elapsed time: 40.105\n",
            "Imputing row 7801/9792 with 1 missing, elapsed time: 40.113\n",
            "Imputing row 7901/9792 with 11 missing, elapsed time: 40.122\n",
            "Imputing row 8001/9792 with 0 missing, elapsed time: 40.129\n",
            "Imputing row 8101/9792 with 0 missing, elapsed time: 40.137\n",
            "Imputing row 8201/9792 with 0 missing, elapsed time: 40.145\n",
            "Imputing row 8301/9792 with 1 missing, elapsed time: 40.152\n",
            "Imputing row 8401/9792 with 1 missing, elapsed time: 40.161\n",
            "Imputing row 8501/9792 with 1 missing, elapsed time: 40.168\n",
            "Imputing row 8601/9792 with 0 missing, elapsed time: 40.176\n",
            "Imputing row 8701/9792 with 1 missing, elapsed time: 40.185\n",
            "Imputing row 8801/9792 with 0 missing, elapsed time: 40.192\n",
            "Imputing row 8901/9792 with 0 missing, elapsed time: 40.199\n",
            "Imputing row 9001/9792 with 1 missing, elapsed time: 40.207\n",
            "Imputing row 9101/9792 with 0 missing, elapsed time: 40.213\n",
            "Imputing row 9201/9792 with 0 missing, elapsed time: 40.219\n",
            "Imputing row 9301/9792 with 1 missing, elapsed time: 40.226\n",
            "Imputing row 9401/9792 with 1 missing, elapsed time: 40.234\n",
            "Imputing row 9501/9792 with 3 missing, elapsed time: 40.245\n",
            "Imputing row 9601/9792 with 1 missing, elapsed time: 40.258\n",
            "Imputing row 9701/9792 with 0 missing, elapsed time: 40.272\n",
            "Imputing row 1/5910 with 0 missing, elapsed time: 13.453\n",
            "Imputing row 101/5910 with 1 missing, elapsed time: 13.461\n",
            "Imputing row 201/5910 with 1 missing, elapsed time: 13.468\n",
            "Imputing row 301/5910 with 0 missing, elapsed time: 13.473\n",
            "Imputing row 401/5910 with 1 missing, elapsed time: 13.476\n",
            "Imputing row 501/5910 with 0 missing, elapsed time: 13.480\n",
            "Imputing row 601/5910 with 1 missing, elapsed time: 13.484\n",
            "Imputing row 701/5910 with 1 missing, elapsed time: 13.488\n",
            "Imputing row 801/5910 with 1 missing, elapsed time: 13.492\n",
            "Imputing row 901/5910 with 0 missing, elapsed time: 13.499\n",
            "Imputing row 1001/5910 with 3 missing, elapsed time: 13.503\n",
            "Imputing row 1101/5910 with 0 missing, elapsed time: 13.508\n",
            "Imputing row 1201/5910 with 1 missing, elapsed time: 13.512\n",
            "Imputing row 1301/5910 with 1 missing, elapsed time: 13.516\n",
            "Imputing row 1401/5910 with 1 missing, elapsed time: 13.521\n",
            "Imputing row 1501/5910 with 0 missing, elapsed time: 13.525\n",
            "Imputing row 1601/5910 with 0 missing, elapsed time: 13.528\n",
            "Imputing row 1701/5910 with 0 missing, elapsed time: 13.532\n",
            "Imputing row 1801/5910 with 1 missing, elapsed time: 13.537\n",
            "Imputing row 1901/5910 with 0 missing, elapsed time: 13.542\n",
            "Imputing row 2001/5910 with 1 missing, elapsed time: 13.547\n",
            "Imputing row 2101/5910 with 1 missing, elapsed time: 13.555\n",
            "Imputing row 2201/5910 with 1 missing, elapsed time: 13.560\n",
            "Imputing row 2301/5910 with 0 missing, elapsed time: 13.566\n",
            "Imputing row 2401/5910 with 1 missing, elapsed time: 13.572\n",
            "Imputing row 2501/5910 with 0 missing, elapsed time: 13.577\n",
            "Imputing row 2601/5910 with 1 missing, elapsed time: 13.583\n",
            "Imputing row 2701/5910 with 1 missing, elapsed time: 13.591\n",
            "Imputing row 2801/5910 with 0 missing, elapsed time: 13.596\n",
            "Imputing row 2901/5910 with 1 missing, elapsed time: 13.601\n",
            "Imputing row 3001/5910 with 0 missing, elapsed time: 13.604\n",
            "Imputing row 3101/5910 with 0 missing, elapsed time: 13.609\n",
            "Imputing row 3201/5910 with 0 missing, elapsed time: 13.614\n",
            "Imputing row 3301/5910 with 4 missing, elapsed time: 13.620\n",
            "Imputing row 3401/5910 with 1 missing, elapsed time: 13.627\n",
            "Imputing row 3501/5910 with 0 missing, elapsed time: 13.631\n",
            "Imputing row 3601/5910 with 1 missing, elapsed time: 13.635\n",
            "Imputing row 3701/5910 with 0 missing, elapsed time: 13.639\n",
            "Imputing row 3801/5910 with 0 missing, elapsed time: 13.644\n",
            "Imputing row 3901/5910 with 0 missing, elapsed time: 13.650\n",
            "Imputing row 4001/5910 with 1 missing, elapsed time: 13.654\n",
            "Imputing row 4101/5910 with 0 missing, elapsed time: 13.664\n",
            "Imputing row 4201/5910 with 0 missing, elapsed time: 13.670\n",
            "Imputing row 4301/5910 with 0 missing, elapsed time: 13.673\n",
            "Imputing row 4401/5910 with 0 missing, elapsed time: 13.676\n",
            "Imputing row 4501/5910 with 1 missing, elapsed time: 13.679\n",
            "Imputing row 4601/5910 with 1 missing, elapsed time: 13.684\n",
            "Imputing row 4701/5910 with 0 missing, elapsed time: 13.688\n",
            "Imputing row 4801/5910 with 0 missing, elapsed time: 13.692\n",
            "Imputing row 4901/5910 with 0 missing, elapsed time: 13.698\n",
            "Imputing row 5001/5910 with 0 missing, elapsed time: 13.704\n",
            "Imputing row 5101/5910 with 1 missing, elapsed time: 13.708\n",
            "Imputing row 5201/5910 with 0 missing, elapsed time: 13.713\n",
            "Imputing row 5301/5910 with 0 missing, elapsed time: 13.718\n",
            "Imputing row 5401/5910 with 0 missing, elapsed time: 13.723\n",
            "Imputing row 5501/5910 with 0 missing, elapsed time: 13.726\n",
            "Imputing row 5601/5910 with 1 missing, elapsed time: 13.732\n",
            "Imputing row 5701/5910 with 5 missing, elapsed time: 13.741\n",
            "Imputing row 5801/5910 with 2 missing, elapsed time: 13.749\n",
            "Imputing row 5901/5910 with 1 missing, elapsed time: 13.759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojeRXjDH602w"
      },
      "source": [
        "def perform_EM_imputation(dfs):\n",
        "    em_imputed_datasets = [impy.imputation.cs.em(dfs[i].values, loops=50, dtype='cont') for i in range(len(dfs))]\n",
        "    return [pd.DataFrame(data=em_imputed_datasets[i]) for i in range(len(dfs))]\n",
        "\n",
        "em_imputed_dataframes = perform_EM_imputation(dataframes)\n",
        "set_new_headers(em_imputed_dataframes)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjemhch062Yz"
      },
      "source": [
        "\n",
        "# # Obtaining the completed features for all the 5 dataframes by doing MICE (Multiple Imputation from Chained Equations)\n",
        "# def perform_MICE_imputation(dfs):\n",
        "#     mice_imputed_datasets = [MICE(verbose=False).fit_transform(dfs[i]) for i in range(len(dfs))]\n",
        "#     return [pd.DataFrame(data=mice_imputed_datasets[i]) for i in range(len(dfs))]\n",
        "    \n",
        "# mice_imputed_dataframes = perform_MICE_imputation(dataframes)\n",
        "# set_new_headers(mice_imputed_dataframes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_rICpUK64N1"
      },
      "source": [
        "imputed_dataframes_dictionary = OrderedDict()\n",
        "imputed_dataframes_dictionary['Mean'] = mean_imputed_dataframes\n",
        "imputed_dataframes_dictionary['k-NN'] = knn_imputed_dataframes\n",
        "imputed_dataframes_dictionary['EM'] = em_imputed_dataframes\n",
        "# imputed_dataframes_dictionary['MICE'] = mice_imputed_dataframes"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyBl8t1c_37Z",
        "outputId": "3067afe6-e675-44ea-dff0-b89fe84004ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def data_imbalance(dfs):\n",
        "    for i in range(len(dfs)):\n",
        "        print('Dataset: '+str(i+1)+'year')\n",
        "        print(dfs[i].groupby('Y').size())\n",
        "        minority_percent = (dfs[i]['Y'].tolist().count(1) / len(dfs[i]['Y'].tolist()))*100\n",
        "        print('Minority (label 1) percentage: '+  str(minority_percent) + '%')\n",
        "        print('-'*64)\n",
        "        \n",
        "data_imbalance(dataframes)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 1year\n",
            "Y\n",
            "0    6756\n",
            "1     271\n",
            "dtype: int64\n",
            "Minority (label 1) percentage: 3.856553294435748%\n",
            "----------------------------------------------------------------\n",
            "Dataset: 2year\n",
            "Y\n",
            "0    9773\n",
            "1     400\n",
            "dtype: int64\n",
            "Minority (label 1) percentage: 3.931976801336872%\n",
            "----------------------------------------------------------------\n",
            "Dataset: 3year\n",
            "Y\n",
            "0    10008\n",
            "1      495\n",
            "dtype: int64\n",
            "Minority (label 1) percentage: 4.712939160239932%\n",
            "----------------------------------------------------------------\n",
            "Dataset: 4year\n",
            "Y\n",
            "0    9277\n",
            "1     515\n",
            "dtype: int64\n",
            "Minority (label 1) percentage: 5.259395424836601%\n",
            "----------------------------------------------------------------\n",
            "Dataset: 5year\n",
            "Y\n",
            "0    5500\n",
            "1     410\n",
            "dtype: int64\n",
            "Minority (label 1) percentage: 6.937394247038917%\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDLDN3P9_40b",
        "outputId": "781bb9be-4f09-42cd-ba4a-36f47699ec8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "def split_dataframes_features_labels(dfs):\n",
        "    feature_dfs = [dfs[i].iloc[:,0:64] for i in range(len(dfs))]\n",
        "    label_dfs = [dfs[i].iloc[:,64] for i in range(len(dfs))]\n",
        "    return feature_dfs, label_dfs    \n",
        "\n",
        "def oversample_data_SMOTENC(dfs, verbose=False):\n",
        "    smotenc = SMOTENC(categorical_features=[0,1], random_state = 42, k_neighbors=10)\n",
        "    feature_dfs, label_dfs = split_dataframes_features_labels(dfs)\n",
        "    resampled_feature_arrays = []\n",
        "    resampled_label_arrays = []\n",
        "    for i in range(len(dfs)):\n",
        "        if verbose: print('Dataset: ' + str(i+1) + 'year:')\n",
        "        if verbose: print('Original dataset shape {}'.format(Counter(label_dfs[i])))\n",
        "        dfi_features_res, dfi_label_res = smotenc.fit_sample(feature_dfs[i], label_dfs[i])\n",
        "        if verbose: print('Resampled dataset shape {}\\n'.format(Counter(dfi_label_res)))\n",
        "        resampled_feature_arrays.append(dfi_features_res)\n",
        "        resampled_label_arrays.append(dfi_label_res)        \n",
        "    return resampled_feature_arrays, resampled_label_arrays\n",
        "\n",
        "def restructure_arrays_to_dataframes(feature_arrays, label_arrays):\n",
        "    resampled_dfs = []\n",
        "    for i in range(len(feature_arrays)):\n",
        "        feature_df = pd.DataFrame(data=feature_arrays[i])\n",
        "        label_df = pd.DataFrame(data=label_arrays[i])\n",
        "        label_df.columns=['Y'] \n",
        "        resampled_dfs.append(feature_df.join(label_df))\n",
        "    set_new_headers(resampled_dfs)    \n",
        "    return resampled_dfs\n",
        "\n",
        "\n",
        "def perform_oversampling_on_imputed_dataframes(df_dict):\n",
        "    imputed_oversampled_dataframes_dictionary = OrderedDict()\n",
        "    for key,dfs in df_dict.items():\n",
        "        print('SMOTE-NC Oversampling for ' + key + ' imputed dataframes\\n')\n",
        "        smotenc_feature_arrays, smotenc_label_arrays = oversample_data_SMOTENC(dfs, verbose=True)\n",
        "        oversampled_dataframes = restructure_arrays_to_dataframes(smotenc_feature_arrays, smotenc_label_arrays)\n",
        "        imputed_oversampled_dataframes_dictionary[key] = oversampled_dataframes\n",
        "        print('-'*100)\n",
        "    return imputed_oversampled_dataframes_dictionary\n",
        "\n",
        "imputed_oversampled_dataframes_dictionary = perform_oversampling_on_imputed_dataframes(imputed_dataframes_dictionary)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SMOTE-NC Oversampling for Mean imputed dataframes\n",
            "\n",
            "Dataset: 1year:\n",
            "Original dataset shape Counter({0.0: 6756, 1.0: 271})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 6756, 1.0: 6756})\n",
            "\n",
            "Dataset: 2year:\n",
            "Original dataset shape Counter({0.0: 9773, 1.0: 400})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 9773, 1.0: 9773})\n",
            "\n",
            "Dataset: 3year:\n",
            "Original dataset shape Counter({0.0: 10008, 1.0: 495})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 10008, 1.0: 10008})\n",
            "\n",
            "Dataset: 4year:\n",
            "Original dataset shape Counter({0.0: 9277, 1.0: 515})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 9277, 1.0: 9277})\n",
            "\n",
            "Dataset: 5year:\n",
            "Original dataset shape Counter({0.0: 5500, 1.0: 410})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 5500, 1.0: 5500})\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "SMOTE-NC Oversampling for k-NN imputed dataframes\n",
            "\n",
            "Dataset: 1year:\n",
            "Original dataset shape Counter({0.0: 6756, 1.0: 271})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 6756, 1.0: 6756})\n",
            "\n",
            "Dataset: 2year:\n",
            "Original dataset shape Counter({0.0: 9773, 1.0: 400})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 9773, 1.0: 9773})\n",
            "\n",
            "Dataset: 3year:\n",
            "Original dataset shape Counter({0.0: 10008, 1.0: 495})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 10008, 1.0: 10008})\n",
            "\n",
            "Dataset: 4year:\n",
            "Original dataset shape Counter({0.0: 9277, 1.0: 515})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 9277, 1.0: 9277})\n",
            "\n",
            "Dataset: 5year:\n",
            "Original dataset shape Counter({0.0: 5500, 1.0: 410})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 5500, 1.0: 5500})\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "SMOTE-NC Oversampling for EM imputed dataframes\n",
            "\n",
            "Dataset: 1year:\n",
            "Original dataset shape Counter({0.0: 6756, 1.0: 271})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 6756, 1.0: 6756})\n",
            "\n",
            "Dataset: 2year:\n",
            "Original dataset shape Counter({0.0: 9773, 1.0: 400})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 9773, 1.0: 9773})\n",
            "\n",
            "Dataset: 3year:\n",
            "Original dataset shape Counter({0.0: 10008, 1.0: 495})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 10008, 1.0: 10008})\n",
            "\n",
            "Dataset: 4year:\n",
            "Original dataset shape Counter({0.0: 9277, 1.0: 515})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 9277, 1.0: 9277})\n",
            "\n",
            "Dataset: 5year:\n",
            "Original dataset shape Counter({0.0: 5500, 1.0: 410})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0.0: 5500, 1.0: 5500})\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRabgdNyGxIq"
      },
      "source": [
        "def prepare_kfold_cv_data(k, X, y, verbose=False):\n",
        "    X = X.values\n",
        "    y = y.values\n",
        "    kf = KFold(n_splits=k, shuffle=False, random_state=42)\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    \n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train.append(X[train_index])\n",
        "        y_train.append(y[train_index])\n",
        "        X_test.append(X[test_index])\n",
        "        y_test.append(y[test_index])\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF47eAVtGzql"
      },
      "source": [
        "gnb_classifier = GaussianNB()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEavIWvgG2PK"
      },
      "source": [
        "rf_classifier = RandomForestClassifier(n_estimators = 5, criterion = 'entropy')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB1pQ-hcG4MY"
      },
      "source": [
        "lgbm_classifier = LGBMClassifier()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Jb2j3QG6ba"
      },
      "source": [
        "models_dictionary = OrderedDict()\n",
        "\n",
        "models_dictionary['Gaussian Naive Bayes'] = gnb_classifier\n",
        "# models_dictionary['Logistic Regression'] = lr_classifier\n",
        "# models_dictionary['Decision Tree'] = dt_classifier\n",
        "# models_dictionary['Extreme Gradient Boosting'] = xgb_classifier\n",
        "models_dictionary['Light Gradient Boosting'] = lgbm_classifier\n",
        "models_dictionary['Random Forest'] = rf_classifier\n",
        "# models_dictionary['Balanced Bagging'] = bb_classifier"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR1PMXB8HBPp"
      },
      "source": [
        "\n",
        "def perform_data_modeling(_models_, _imputers_, verbose=False, k_folds=5):\n",
        "    \n",
        "    model_results = OrderedDict()\n",
        "    \n",
        "\n",
        "    for model_name, clf in _models_.items():\n",
        "        if verbose: print(\"-\"*120, \"\\n\", \"Model: \" + '\\033[1m' + model_name + '\\033[0m' + \" Classifier\")\n",
        "        imputer_results = OrderedDict()\n",
        "        \n",
        "\n",
        "        for imputer_name, dataframes_list in _imputers_.items():\n",
        "            if verbose: print('\\tImputer Technique: ' + '\\033[1m' + imputer_name + '\\033[0m')\n",
        "            feature_dfs, label_dfs = split_dataframes_features_labels(dataframes_list)            \n",
        "            year_results = OrderedDict()\n",
        "            \n",
        "            \n",
        "            \n",
        "            for df_index in range(len(dataframes_list)):\n",
        "                if verbose: print('\\t\\tDataset: ' + '\\033[1m' + str(df_index+1) + 'year' + '\\033[0m')\n",
        "                X_train_list, y_train_list, X_test_list, y_test_list = prepare_kfold_cv_data(k_folds, feature_dfs[df_index], label_dfs[df_index], verbose)\n",
        "                metrics_results = OrderedDict()\n",
        "                accuracy_list = np.zeros([k_folds])\n",
        "                precision_list = np.zeros([k_folds,2])\n",
        "                recall_list = np.zeros([k_folds,2]) \n",
        "                TN_list = np.zeros([k_folds])\n",
        "                FP_list = np.zeros([k_folds])\n",
        "                FN_list = np.zeros([k_folds])\n",
        "                TP_list = np.zeros([k_folds])                \n",
        "                \n",
        "\n",
        "                for k_index in range(k_folds):\n",
        "                    X_train = X_train_list[k_index]\n",
        "                    y_train = y_train_list[k_index]\n",
        "                    X_test = X_test_list[k_index]\n",
        "                    y_test = y_test_list[k_index]\n",
        "                    \n",
        "\n",
        "                    clf = clf.fit(X_train, y_train)\n",
        "                    y_test_predicted = clf.predict(X_test)\n",
        "                    \n",
        "\n",
        "                    _accuracy_ = accuracy_score(y_test, y_test_predicted, normalize=True)\n",
        "                    accuracy_list[k_index] = _accuracy_\n",
        "                    \n",
        "\n",
        "                    _recalls_ = recall_score(y_test, y_test_predicted, average=None)\n",
        "                    recall_list[k_index] = _recalls_\n",
        "                    \n",
        "\n",
        "                    _precisions_ = precision_score(y_test, y_test_predicted, average=None)\n",
        "                    precision_list[k_index] = _precisions_\n",
        "                    \n",
        "\n",
        "                    _confusion_matrix_ = confusion_matrix(y_test, y_test_predicted)\n",
        "                    TN_list[k_index] = _confusion_matrix_[0][0]\n",
        "                    FP_list[k_index] = _confusion_matrix_[0][1]\n",
        "                    FN_list[k_index] = _confusion_matrix_[1][0]\n",
        "                    TP_list[k_index] = _confusion_matrix_[1][1]\n",
        "                \n",
        "\n",
        "                metrics_results['Accuracy'] = np.mean(accuracy_list)\n",
        "                metrics_results['Precisions'] = np.mean(precision_list, axis=0)\n",
        "                metrics_results['Recalls'] = np.mean(recall_list, axis=0)\n",
        "                metrics_results['TN'] = np.mean(TN_list)\n",
        "                metrics_results['FP'] = np.mean(FP_list)\n",
        "                metrics_results['FN'] = np.mean(FN_list)\n",
        "                metrics_results['TP'] = np.mean(TP_list)\n",
        "                \n",
        "                if verbose:\n",
        "                    print('\\t\\t\\tAccuracy:', metrics_results['Accuracy'])\n",
        "                    print('\\t\\t\\tPrecision:', metrics_results['Precisions'])\n",
        "                    print('\\t\\t\\tRecall:', metrics_results['Recalls'])\n",
        "                \n",
        "                year_results[str(df_index+1)+'year'] = metrics_results   \n",
        "                \n",
        "            imputer_results[imputer_name] = year_results\n",
        "            \n",
        "        model_results[model_name] = imputer_results  \n",
        "        \n",
        "    return model_results"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzQ7KxAbKPf_"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFVzDdkZHFRj",
        "outputId": "3b38b605-eb4e-401d-b562-67526ede4528",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results = perform_data_modeling(models_dictionary, imputed_oversampled_dataframes_dictionary, verbose=True, k_folds=5)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mGaussian Naive Bayes\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5155378252581706\n",
            "\t\t\tPrecision: [0.55384615 0.50140311]\n",
            "\t\t\tRecall: [0.02420356 0.59385805]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.512558270997678\n",
            "\t\t\tPrecision: [0.50338983 0.50013189]\n",
            "\t\t\tRecall: [0.02512063 0.58761981]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5195579838597576\n",
            "\t\t\tPrecision: [0.53333333 0.50124288]\n",
            "\t\t\tRecall: [0.03487385 0.58701092]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5145220917487967\n",
            "\t\t\tPrecision: [0.51151515 0.50056402]\n",
            "\t\t\tRecall: [0.03805172 0.5774722 ]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5165454545454546\n",
            "\t\t\tPrecision: [0.51652174 0.50091127]\n",
            "\t\t\tRecall: [0.04136364 0.57690909]\n",
            "\tImputer Technique: \u001b[1mk-NN\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5167212842708693\n",
            "\t\t\tPrecision: [0.54647887 0.50133029]\n",
            "\t\t\tRecall: [0.0267936  0.59230408]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5116884964136144\n",
            "\t\t\tPrecision: [0.51034483 0.50034274]\n",
            "\t\t\tRecall: [0.02476257 0.58751735]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5201073096276694\n",
            "\t\t\tPrecision: [0.53509934 0.50140187]\n",
            "\t\t\tRecall: [0.03747183 0.58526228]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5134441715857496\n",
            "\t\t\tPrecision: [0.51098266 0.50056529]\n",
            "\t\t\tRecall: [0.03783626 0.57660998]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5256363636363637\n",
            "\t\t\tPrecision: [0.52112676 0.50145773]\n",
            "\t\t\tRecall: [0.05309091 0.57527273]\n",
            "\tImputer Technique: \u001b[1mEM\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5135393604112874\n",
            "\t\t\tPrecision: [0.5260274  0.50079878]\n",
            "\t\t\tRecall: [0.02346298 0.59141672]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5094374121232463\n",
            "\t\t\tPrecision: [0.51092437 0.50036939]\n",
            "\t\t\tRecall: [0.02460926 0.58547082]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5277006905160789\n",
            "\t\t\tPrecision: [0.53898305 0.50182959]\n",
            "\t\t\tRecall: [0.04646469 0.58466285]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5116656316436674\n",
            "\t\t\tPrecision: [0.50564103 0.5003413 ]\n",
            "\t\t\tRecall: [0.03912991 0.57310727]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.5356363636363637\n",
            "\t\t\tPrecision: [0.50356633 0.57731959]\n",
            "\t\t\tRecall: [0.26572727 0.37672727]\n",
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mLight Gradient Boosting\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9846796319466294\n",
            "\t\t\tPrecision: [0.58248473 0.5990236 ]\n",
            "\t\t\tRecall: [0.59474559 0.57995491]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9822470278110911\n",
            "\t\t\tPrecision: [0.58212447 0.59909707]\n",
            "\t\t\tRecall: [0.59294009 0.57913009]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9758192719097041\n",
            "\t\t\tPrecision: [0.57794643 0.59909246]\n",
            "\t\t\tRecall: [0.58980858 0.57327621]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9692262894389158\n",
            "\t\t\tPrecision: [0.57251052 0.59872774]\n",
            "\t\t\tRecall: [0.58728077 0.56557005]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9687272727272728\n",
            "\t\t\tPrecision: [0.57398244 0.59788807]\n",
            "\t\t\tRecall: [0.58454545 0.56845455]\n",
            "\tImputer Technique: \u001b[1mk-NN\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9798695037698334\n",
            "\t\t\tPrecision: [0.58063215 0.59884774]\n",
            "\t\t\tRecall: [0.59156378 0.57714382]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9742658917482705\n",
            "\t\t\tPrecision: [0.57850253 0.59872979]\n",
            "\t\t\tRecall: [0.58787522 0.57386133]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9679253796415924\n",
            "\t\t\tPrecision: [0.57250979 0.59788732]\n",
            "\t\t\tRecall: [0.58616125 0.56508408]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9613577758554193\n",
            "\t\t\tPrecision: [0.5704461  0.59730597]\n",
            "\t\t\tRecall: [0.58038204 0.56271436]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9570000000000001\n",
            "\t\t\tPrecision: [0.56745971 0.59799331]\n",
            "\t\t\tRecall: [0.57754545 0.55936364]\n",
            "\tImputer Technique: \u001b[1mEM\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9823855830336827\n",
            "\t\t\tPrecision: [0.58148649 0.59885434]\n",
            "\t\t\tRecall: [0.59311761 0.57862344]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9817352964075952\n",
            "\t\t\tPrecision: [0.58060325 0.5990878 ]\n",
            "\t\t\tRecall: [0.59294    0.57769797]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9738707333136511\n",
            "\t\t\tPrecision: [0.57337973 0.59906103]\n",
            "\t\t\tRecall: [0.59055802 0.56763192]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9721366288465632\n",
            "\t\t\tPrecision: [0.5727783  0.59898284]\n",
            "\t\t\tRecall: [0.58900543 0.56702517]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9687272727272728\n",
            "\t\t\tPrecision: [0.57420382 0.59872881]\n",
            "\t\t\tRecall: [0.58418182 0.56927273]\n",
            "------------------------------------------------------------------------------------------------------------------------ \n",
            " Model: \u001b[1mRandom Forest\u001b[0m Classifier\n",
            "\tImputer Technique: \u001b[1mMean\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9606293196719493\n",
            "\t\t\tPrecision: [0.58717407 0.59657054]\n",
            "\t\t\tRecall: [0.57631899 0.57595371]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9499134334236882\n",
            "\t\t\tPrecision: [0.58322892 0.59422028]\n",
            "\t\t\tRecall: [0.56904737 0.569255  ]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9393991718997965\n",
            "\t\t\tPrecision: [0.58234183 0.59257294]\n",
            "\t\t\tRecall: [0.56013187 0.56642985]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9238992839093509\n",
            "\t\t\tPrecision: [0.578125   0.58980892]\n",
            "\t\t\tRecall: [0.54928335 0.55818206]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9282727272727274\n",
            "\t\t\tPrecision: [0.58372703 0.59053926]\n",
            "\t\t\tRecall: [0.55209091 0.56318182]\n",
            "\tImputer Technique: \u001b[1mk-NN\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9353937136493075\n",
            "\t\t\tPrecision: [0.57955182 0.58932496]\n",
            "\t\t\tRecall: [0.55611165 0.56345048]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9312398105493322\n",
            "\t\t\tPrecision: [0.58134615 0.59256424]\n",
            "\t\t\tRecall: [0.55497812 0.56286003]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9174168449586885\n",
            "\t\t\tPrecision: [0.58017241 0.58746736]\n",
            "\t\t\tRecall: [0.54354425 0.55753702]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9115570595468705\n",
            "\t\t\tPrecision: [0.57774406 0.58869666]\n",
            "\t\t\tRecall: [0.54141456 0.5530078 ]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9088181818181817\n",
            "\t\t\tPrecision: [0.57335554 0.58818819]\n",
            "\t\t\tRecall: [0.54345455 0.54545455]\n",
            "\tImputer Technique: \u001b[1mEM\u001b[0m\n",
            "\t\tDataset: \u001b[1m1year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9501941670206062\n",
            "\t\t\tPrecision: [0.5837914  0.59282931]\n",
            "\t\t\tRecall: [0.5685459  0.56973872]\n",
            "\t\tDataset: \u001b[1m2year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9429558255949448\n",
            "\t\t\tPrecision: [0.58187106 0.5915493 ]\n",
            "\t\t\tRecall: [0.56229377 0.56710645]\n",
            "\t\tDataset: \u001b[1m3year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9323050169915021\n",
            "\t\t\tPrecision: [0.57757183 0.59078591]\n",
            "\t\t\tRecall: [0.55393667 0.56203452]\n",
            "\t\tDataset: \u001b[1m4year\u001b[0m\n",
            "\t\t\tAccuracy: 0.924007492840183\n",
            "\t\t\tPrecision: [0.57850988 0.58918297]\n",
            "\t\t\tRecall: [0.54631902 0.56120039]\n",
            "\t\tDataset: \u001b[1m5year\u001b[0m\n",
            "\t\t\tAccuracy: 0.9240909090909092\n",
            "\t\t\tPrecision: [0.57646063 0.58861629]\n",
            "\t\t\tRecall: [0.55045455 0.55572727]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}